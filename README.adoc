= Large-Language Model (LLM) part of Talk2PowerSystem
v0.1.0, 2025-02-24
:toc:
:toclevels: 2

== Overview

Large-Language Model (LLM) part of Talk2PowerSystem (Talk2PowerSystem_LLM) is a core component of the Talk2PowerSystem
project, providing all the necessary coding and scripting to support the integration and operation of a Large-Language
Model (LLM). This project focuses on enabling robust LLM functionalities, including data preprocessing, model training,
inference, and seamless integration with other parts of the Talk2PowerSystem ecosystem.

== Features

* **Data Preprocessing:**  
  Scripts to clean, normalize, and format data for LLM training.

* **Model Training:**  
  Pipelines and utilities for fine-tuning and training LLM models.

* **Inference Engine:**  
  Code for running real-time queries and generating model predictions.

* **System Integration:**  
  Tools and interfaces to connect the LLM with other components of the Talk2PowerSystem project.

* **Testing and Evaluation:**  
  Automated tests and performance evaluation scripts to ensure model reliability and accuracy.

== Project Structure

The repository is organized as follows:

* `src/` - Main source code including training, inference, and integration scripts.
* `data/` - Data sets and preprocessing scripts.
* `docs/` - Documentation, guides, and technical notes.
* `tests/` - Unit and integration tests for various modules.
* `config/` - Configuration files for model parameters and environment settings.
* `evaluation_results/` - Directory, which holds the evaluation results of the system.
* `helm-chart/` - Directory, which holds resources for easier deployment on Kubernetes environments.

== Installation

=== Prerequisites

* You should install https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html[conda]. `miniconda` will suffice.

=== Setup

To set up the project locally, follow these steps:

1. Clone the repository:
+
[,bash]
----
git clone https://github.com/statnett/Talk2PowerSystem_LLM.git
----

2. Create a conda environment and install dependencies
+
[,bash]
----
conda create --name Talk2PowerSystemLLM --file conda-linux-64.lock
conda activate Talk2PowerSystemLLM
poetry install
----

== Run tests

=== Unit tests
[,bash]
----
conda activate Talk2PowerSystemLLM
poetry install --with test
poetry run pytest --cov=talk2powersystemllm --cov-report=term-missing tests/unit_tests/
----

=== Acceptance tests
[,bash]
----
cp src/talk2powersystemllm/app/dummy-manifest.yaml git-manifest.yaml
docker buildx build --file docker/Dockerfile --tag talk2powersystem .
docker buildx build --file tests/acceptance_tests/docker-compose/DockerfileAcceptanceTests --tag talk2powersystem-acceptance-tests .
docker buildx build --file tests/acceptance_tests/docker-compose/DockerfileGraphDB --tag graphdb .
docker compose -f tests/acceptance_tests/docker-compose/docker-compose.yaml run --rm talk2powersystem-acceptance-tests poetry run pytest tests/acceptance_tests/
docker compose -f tests/acceptance_tests/docker-compose/docker-compose.yaml down -v --remove-orphans
----

== Versioning

The chat bot releases follow the https://semver.org/[Semantic Versioning Standard].

Steps to release (from the main branch):

. `conda activate Talk2PowerSystemLLM`
. `poetry version <major|minor|patch>`.
. `git add pyproject.toml`
. `git commit -m "Bumping version from <previous-version> to <current-version>"`
. `git push -u origin main`
. Create a release from https://github.com/statnett/Talk2PowerSystem_LLM/releases[the GitHub interface]. The tag and the release title must match the version from poetry!
. Edit the `version` in `pyproject.toml` - increase the `patch` and add `-dev0` after it. For example, if the version is `1.1.123`, the new version must be `1.1.124-dev0`.
. `git add pyproject.toml`
. `git commit -m "Bumping version from <previous-version> to <current-version>"`
. `git push -u origin main`

== License

Talk2PowerSystem_LLM is licensed under the Apache License 2.0. For more information, see the `LICENSE` file.
