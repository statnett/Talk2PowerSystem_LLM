# Talk2PowerSystem Agent Config

The configuration is expected in yaml format. Below is given an example:

```yaml
graphdb:
  base_url: "https://cim.ontotext.com/graphdb"
  repository_id: "cim"
  connect_timeout: 2
  read_timeout: 10
  sparql_timeout: 15
  username: "admin"
tools:
  ontology_schema:
    file_path: "ontology/cim-subset-pretty.ttl"
  autocomplete_search:
    property_path: "<https://cim.ucaiug.io/ns#IdentifiedObject.name> | <https://cim.ucaiug.io/ns#IdentifiedObject.aliasName> | <https://cim.ucaiug.io/ns#CoordinateSystem.crsUrn>"
    sparql_query_template: |
      PREFIX sesame: <http://www.openrdf.org/schema/sesame#>
      PREFIX rank: <http://www.ontotext.com/owlim/RDFRank#>
      PREFIX auto: <http://www.ontotext.com/plugins/autocomplete#>
      SELECT ?iri ?name ?class ?rank {{
          ?iri auto:query "{query}" ;
              {property_path} ?name ;
              {filter_clause}
              sesame:directType ?class;
              rank:hasRDFRank5 ?rank.
      }}
      ORDER BY DESC(?rank)
      LIMIT {limit}
  retrieval_search:
    graphdb:
      base_url: "http://localhost:7200"
      repository_id: "qa_dataset"
      connect_timeout: 2
      read_timeout: 10
      sparql_timeout: 15
    connector_name: "qa_dataset"
    name: sample_sparql_queries
    description: Given a user question obtain sample SPARQL queries, which can be used to answer the question
    sparql_query_template: |
      PREFIX retr: <http://www.ontotext.com/connectors/retrieval#>
      PREFIX retr-index: <http://www.ontotext.com/connectors/retrieval/instance#>
      PREFIX qa: <https://www.statnett.no/Talk2PowerSystem/qa#>
      SELECT ?question ?query {{
          [] a retr-index:{connector_name} ;
            retr:query "{query}" ;
            retr:limit {limit} ;
            retr:entities ?entity .
          ?entity retr:score ?score;
            qa:question ?question;
            qa:sparql_query ?query.
          FILTER (?score > {score})
      }}
      ORDER BY DESC(?score)
  cognite:
    base_url: https://statnett.cognitedata.com
    client_name: talk2powersystem
    project: prod
    interactive_client_id: 0d448de6-4574-44af-9a3b-2bd0304cfa36
    tenant_id: a8d61462-f252-44b2-bf6a-d7231960c041
llm:
  azure_endpoint: "https://statnett.openai.azure.com/"
  model: "gpt-4.1"
  api_version: "2024-12-01-preview"
  temperature: 0
  seed: 1
  timeout: 120
prompts:
  assistant_instructions: |
    Role & Objective:
      You are a natural language querying assistant. Your goal is to answer users' questions related to electricity data, including:
        - A power grid model
        - Time-series data for power generation and consumption, and electricity prices

    ...

    The ontology schema to use in SPARQL queries is:

    ```turtle
    {ontology_schema}
    ```

    ...
```

## `graphdb`

- `graphdb.base_url` - REQUIRED - Base URL of the GraphDB server.
- `graphdb.repository_id` - REQUIRED - Repository ID in GraphDB to query against.
- `graphdb.connect_timeout` - OPTIONAL, DEFAULT=`2` - Connect timeout in seconds for calls to GraphDB REST API, must be >= 1.
- `graphdb.read_timeout` - OPTIONAL, DEFAULT=`10` - Read timeout in seconds for calls to GraphDB REST API, must be >= 1.
- `graphdb.sparql_timeout` - OPTIONAL, DEFAULT=`15` - Timeout in seconds for calls to the SPARQL endpoint, must be >= 1.
- `graphdb.username` - OPTIONAL - Username for GraphDB authentication. If it's provided, it's mandatory to have an
  environment variable `GRAPHDB_PASSWORD` storing the password for this user.

## `tools`

### `tools.ontology_schema`

- `tools.ontology_schema.file_path` - REQUIRED - Path to the ontology schema file in turtle format. The path must be
  relevant to the agent config yaml file.

### `tools.autocomplete_search`

- `tools.autocomplete_search.property_path` - REQUIRED - SPARQL property path for matching search terms.
- `tools.autocomplete_search.sparql_query_template` - OPTIONAL - SPARQL query template for autocomplete search.
  `{` and `}` symbols must be written like `{{` and `}}`.
  Placeholders: `{query}`, `{property_path}`, `{filter_clause}`, `{limit}`.
  All placeholders except `{filter_clause}` are arguments generated by the LLM agent.
  `{filter_clause}` is replaced with ` a {result_class} ;` if the LLM agent generates the optional `result_class`
  argument for filtering of the results; otherwise it's replaced with an empty string.
  If not provided, defaults to the one
  from [ttyg-langgraph](https://github.com/Ontotext-AD/ttyg-langgraph/blob/main/ttyg/tools/graphdb_tools/autocomplete_search_tool.py#L35),
  i.e.

```
PREFIX rank: <http://www.ontotext.com/owlim/RDFRank#>
PREFIX auto: <http://www.ontotext.com/plugins/autocomplete#>
SELECT ?iri ?name ?rank {{
  ?iri auto:query "{query}" ;
  {property_path} ?name ;{filter_clause}
  rank:hasRDFRank5 ?rank.
}}
ORDER BY DESC(?rank)
LIMIT {limit}
```

### `tools.retrieval_search` - OPTIONAL - if not present, the `Retrieval Tool` (`N-Shot`) tool won't be present

- `tools.retrieval_search.connector_name` - REQUIRED - Name of the retrieval connector instance.
- `tools.retrieval_search.name` - REQUIRED - Name of the tool.
- `tools.retrieval_search.description` - REQUIRED - Description of the tool.
- `tools.retrieval_search.sparql_query_template` - REQUIRED - SPARQL query template for search.
  `{` and `}` symbols must be written like `{{` and `}}`.
  Placeholders: `{query}`, `{limit}`, `{score}` (the arguments generated by the LLM agent).

#### `tools.retrieval_search.graphdb`

When Weaviate, Ontotext Embedding API and Ontotext Retrieval Plugin API are deployed on the RNDP environment or on the
CIM environment,
these must be removed and should be the same as the ones from `graphdb`.
However, for the time being and for the purposes of the experiments we keep these separate, i.e.
we create a local environment using a docker compose setup.

- `tools.retrieval_search.graphdb.base_url` - REQUIRED - Base URL of the GraphDB server.
- `tools.retrieval_search.graphdb.repository_id` - REQUIRED - Repository ID in GraphDB to query against.
- `tools.retrieval_search.graphdb.connect_timeout` - OPTIONAL, DEFAULT=`2` - Connect timeout in seconds for calls to GraphDB REST API, must be >= 1.
- `tools.retrieval_search.graphdb.read_timeout` - OPTIONAL, DEFAULT=`10` - Read timeout in seconds for calls to GraphDB REST API, must be >= 1.
- `tools.retrieval_search.graphdb.sparql_timeout` - OPTIONAL, DEFAULT=`15` - Timeout in seconds for calls to the SPARQL endpoint, must be >= 1.

### `tools.cognite` - OPTIONAL - if not present, the `Cognite Query Tools` won't be present

- `tools.cognite.base_url` - REQUIRED - Base URL for the Cognite API. For example, `https://statnett.cognitedata.com`.
- `tools.cognite.project` - OPTIONAL, DEFAULT=`prod` - Cognite Data Fusion project name.
One of `dev1`, `dev2`, `dev3`, `test`, `prod` according to [CDF access from RNDP](https://github.com/statnett/Talk2PowerSystem_PM/wiki/CDF-access-from-RNDP).
- `tools.cognite.client_name` - OPTIONAL, DEFAULT=`talk2powersystem` - Name of the client for logging purposes.
- `tools.cognite.interactive_client_id` - OPTIONAL - If provided, interactive authentication is used.
  Otherwise, `tools.cognite.token_file_path` must be provided for client credentials authentication.
- `tools.cognite.tenant_id` - REQUIRED iff `tools.cognite.interactive_client_id` is present - Azure tenant ID. For example, `a8d61462-f252-44b2-bf6a-d7231960c041`.
- `tools.cognite.token_file_path` - OPTIONAL - Full path on the disk to the cognite token file. For example, `/var/run/secrets/microsoft.com/entra/cognite`.

## `llm`

- `llm.type` - OPTIONAL, DEFAULT=`azure_openai`, can be `openai` or `azure_openai` - The LLM deployment type.
- `llm.model` - REQUIRED - Azure OpenAI deployment name, if `llm.type=azure_openai`; otherwise the model name.
The API key must be provided using the environment variable `LLM_API_KEY`.
- `llm.azure_endpoint` - OPTIONAL, REQUIRED, iff `llm.type=azure_openai` - Azure OpenAI API endpoint.
- `llm.api_version` - OPTIONAL, REQUIRED, iff `llm.type=azure_openai` - API version for Azure OpenAI.
- `llm.temperature` - OPTIONAL, DEFAULT=`0`, float value greater than or equal to 0, and less than or equal to 2 -
  Sampling temperature for the LLM. Lower values indicate more deterministic results.
- `llm.seed` - OPTIONAL, DEFAULT=`1`, integer - Random seed for reproducibility.
- `llm.timeout` - OPTIONAL, DEFAULT=`120`, integer - Timeout in seconds for LLM API calls.

## `prompts`

- `prompts.assistant_instructions` - REQUIRED - Assistant / agent instructions. The placeholder `{ontology_schema}` is
  replaced with the ontology schema definition in turtle.

## Environment variables / Secrets

- `LLM_API_KEY` - REQUIRED - API key for authentication to Azure OpenAI or OpenAI
- `GRAPHDB_PASSWORD` - REQUIRED, iff `graphdb.username` is set - Password for the GraphDB user
